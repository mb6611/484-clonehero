{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor, Pop2PianoTokenizer\n",
    "from encoder import encode_plus\n",
    "import sys\n",
    "sys.path.append(\"./pop2piano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def crop_midi(midi, start_beat, end_beat, extrapolated_beatsteps):\n",
    "    start = extrapolated_beatsteps[start_beat]\n",
    "    end = extrapolated_beatsteps[end_beat]\n",
    "    out = copy.deepcopy(midi)\n",
    "    for note in out.instruments[0].notes.copy():\n",
    "        if note.start > end or note.start < start:\n",
    "            out.instruments[0].notes.remove(note)\n",
    "        # interpolate index of start note\n",
    "\n",
    "        lower = np.argmax(extrapolated_beatsteps[extrapolated_beatsteps <= note.start])\n",
    "        note.start = lower\n",
    "        note.start = int(note.start - start_beat)\n",
    "\n",
    "        lower = np.argmax(extrapolated_beatsteps[extrapolated_beatsteps <= note.end])\n",
    "        note.end = lower\n",
    "        note.end = int(note.end - start_beat)\n",
    "        if note.end == note.start:\n",
    "            note.end += 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model, processor, and tokenizer.\n"
     ]
    }
   ],
   "source": [
    "model = Pop2PianoForConditionalGeneration.from_pretrained(\"./cache/model\")\n",
    "processor = Pop2PianoProcessor.from_pretrained(\"./cache/processor\")\n",
    "tokenizer = Pop2PianoTokenizer.from_pretrained(\"./cache/tokenizer\")\n",
    "\n",
    "print(\"Loaded pretrained model, processor, and tokenizer.\")\n",
    "# cache the model, processor, and tokenizer to avoid downloading them again\n",
    "# model.save_pretrained(\"./cache/model\")\n",
    "# processor.save_pretrained(\"./cache/processor\")\n",
    "# tokenizer.save_pretrained(\"./cache/tokenizer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an example audio file and corresponding ground truth midi file\n",
    "audio_path = \"./processed/audio/Mountain - Mississippi Queen.ogg\"\n",
    "# audio_path = \"./processed/audio/Aerosmith - Same Old Song & Dance.ogg\"\n",
    "audio, sr = librosa.load(audio_path, sr=44100)  # feel free to change the sr to a suitable value.\n",
    "\n",
    "# convert the audio file to tokens\n",
    "inputs = processor(audio=audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# load ground truth midi file\n",
    "# midi = pretty_midi.PrettyMIDI(\"./processed/midi/Mountain - Mississippi Queen.mid\")\n",
    "# ground_truth_midi_path = \"./processed/midi/Mountain - Mississippi Queen.mid\"\n",
    "# ground_truth_midi_path = \"mountain_out_gen.mid\"\n",
    "ground_truth_midi_path = \"./processed/piano_midi/Aerosmith - Same Old Song & Dance.mid\"\n",
    "midi = pretty_midi.PrettyMIDI(ground_truth_midi_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([711])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.beatsteps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the midi file to tokens\n",
    "batches = [crop_midi(midi, i, i+8, inputs.extrapolated_beatstep[0]).instruments[0].notes for i in range(2, len(inputs.extrapolated_beatstep[0])-10, 8)]\n",
    "# # remove empty batches\n",
    "# batches = [batch for batch in batches if len(batch) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Note(start=0.000000, end=1.000000, pitch=74, velocity=77),\n",
       " Note(start=1.000000, end=2.000000, pitch=74, velocity=77),\n",
       " Note(start=2.000000, end=4.000000, pitch=43, velocity=77),\n",
       " Note(start=2.000000, end=4.000000, pitch=55, velocity=77),\n",
       " Note(start=2.000000, end=4.000000, pitch=62, velocity=77),\n",
       " Note(start=2.000000, end=4.000000, pitch=67, velocity=77),\n",
       " Note(start=2.000000, end=4.000000, pitch=69, velocity=77),\n",
       " Note(start=4.000000, end=5.000000, pitch=55, velocity=77),\n",
       " Note(start=5.000000, end=6.000000, pitch=55, velocity=77),\n",
       " Note(start=6.000000, end=7.000000, pitch=57, velocity=77),\n",
       " Note(start=6.000000, end=8.000000, pitch=45, velocity=77),\n",
       " Note(start=7.000000, end=8.000000, pitch=57, velocity=77)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs.beatsteps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.875"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "711/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model.generate(inputs[\"input_features\"], generation_config=model.generation_config, return_dict_in_generate=True, output_logits=True, )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 134 133  56 135 132  56 133  44  56 135 132  44  56 133  44  56 135\n",
      " 132  44  56 133  46  58  66 135 132  46  58  66 133  47  59  66 135 132\n",
      "  47  59 133  47  59 135 132  47  59 133  47  59 135 132  47  59 133  47\n",
      "  59  71 136 132  47  59  71 135  66   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "offset = 0\n",
    "for batch in batches:\n",
    "    # print(f\"outer offset: {offset}\")\n",
    "    label, offset = encode_plus(tokenizer, batch, return_tensors=\"pt\", time_offset=0)        \n",
    "    labels.append(label[\"token_ids\"])\n",
    "labels = [np.append([0], np.append(label, [1, 0])) for label in labels]\n",
    "# longest_length = max([len(label) for label in labels])\n",
    "longest_length = len(model_output.sequences[0])\n",
    "padded_labels = np.array([np.pad(label, (0, longest_length - len(label))) for label in labels])\n",
    "print(padded_labels[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_convert(t_labels, vocab_size):\n",
    "    # Your vocabulary size\n",
    "    vocab_size = 2400\n",
    "\n",
    "    # Create a tensor to hold the one-hot encoded versions\n",
    "    one_hot_tensor = torch.zeros((*t_labels.shape, vocab_size))\n",
    "\n",
    "    # Iterate over each element of the original tensor\n",
    "    for i in range(t_labels.size(0)):\n",
    "        for j in range(t_labels.size(1)):\n",
    "            # Get the value from the original tensor\n",
    "            value = int(t_labels[i, j])\n",
    "            # One-hot encode the value\n",
    "            one_hot = torch.zeros(vocab_size)\n",
    "            one_hot[value] = 1\n",
    "            # Assign it to the corresponding position in the new tensor\n",
    "            one_hot_tensor[i, j] = one_hot\n",
    "    return one_hot_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89, 107, 2400])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "loss_fct = CrossEntropyLoss()\n",
    "logits = torch.stack(model_output.logits)\n",
    "print(logits.transpose(0,1).shape)\n",
    "t_labels = torch.tensor(padded_labels)\n",
    "t_labels = t_labels[:,1:]\n",
    "one_hot = one_hot_convert(t_labels, 2400)\n",
    "# generate one hot from t_labels\n",
    "\n",
    "# print(t_labels.shape)\n",
    "loss = loss_fct(logits.transpose(0,1), one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5809)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
