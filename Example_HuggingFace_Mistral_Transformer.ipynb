{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SiTIpPjArIyr"
   },
   "source": [
    "# Full example with the Hugging Face Transformers package\n",
    "\n",
    "This notebook shows how to train a model (Mistral) and generate music with it, using the Hugging Face Transformers package."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gOd93yV0sGd2"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "fX12Yquyuihc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting miditok\n",
      "  Downloading miditok-3.0.3-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.16.4 in ./lib/python3.10/site-packages (from miditok) (0.23.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in ./lib/python3.10/site-packages (from miditok) (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.19 in ./lib/python3.10/site-packages (from miditok) (1.26.4)\n",
      "Requirement already satisfied: tqdm in ./lib/python3.10/site-packages (from miditok) (4.66.2)\n",
      "Collecting symusic>=0.4.3\n",
      "  Downloading symusic-0.4.7-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in ./lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (6.0.1)\n",
      "Requirement already satisfied: filelock in ./lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./lib/python3.10/site-packages (from huggingface-hub>=0.16.4->miditok) (2024.3.1)\n",
      "Collecting pySmartDL\n",
      "  Downloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: platformdirs in ./lib/python3.10/site-packages (from symusic>=0.4.3->miditok) (4.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests->huggingface-hub>=0.16.4->miditok) (2.2.1)\n",
      "Installing collected packages: pySmartDL, symusic, miditok\n",
      "Successfully installed miditok-3.0.3 pySmartDL-1.3.4 symusic-0.4.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: symusic in ./lib/python3.10/site-packages (0.4.7)\n",
      "Requirement already satisfied: platformdirs in ./lib/python3.10/site-packages (from symusic) (4.2.1)\n",
      "Requirement already satisfied: pySmartDL in ./lib/python3.10/site-packages (from symusic) (1.3.4)\n",
      "Requirement already satisfied: numpy in ./lib/python3.10/site-packages (from symusic) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in ./lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: triton==2.3.0 in ./lib/python3.10/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in ./lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: sympy in ./lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in ./lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: fsspec in ./lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in ./lib/python3.10/site-packages (4.40.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: filelock in ./lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: requests in ./lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./lib/python3.10/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in ./lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: psutil in ./lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in ./lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: filelock in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: triton==2.3.0 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: sympy in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: fsspec in ./lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in ./lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.29.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Collecting datasets>=2.0.0\n",
      "  Using cached datasets-2.19.0-py3-none-any.whl (542 kB)\n",
      "Requirement already satisfied: packaging in ./lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./lib/python3.10/site-packages (from evaluate) (0.23.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./lib/python3.10/site-packages (from evaluate) (2024.3.1)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Collecting pyarrow-hotfix\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Using cached pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: filelock in ./lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, attrs, async-timeout, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 datasets-2.19.0 dill-0.3.8 evaluate-0.4.2 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-16.0.0 pyarrow-hotfix-0.6 pytz-2024.1 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in ./lib/python3.10/site-packages (from tensorboard) (59.6.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.0.2-py3-none-any.whl (226 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: six>1.9 in ./lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.63.0 markdown-3.6 protobuf-5.26.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 werkzeug-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in ./lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%wget` not found.\n"
     ]
    }
   ],
   "source": [
    "#@title Install all dependencies (run only once per session)\n",
    "\n",
    "# Run the following command only if a nvidia driver is installed\n",
    "#%nvidia-smi\n",
    "\n",
    "%pip install miditok\n",
    "%pip install symusic\n",
    "%pip install torch\n",
    "%pip install transformers\n",
    "%pip install accelerate\n",
    "%pip install evaluate\n",
    "%pip install tensorboard\n",
    "%pip install scikit-learn\n",
    "\n",
    "#%wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n",
    "#%unzip 'maestro-v3.0.0-midi.zip'\n",
    "#%rm 'maestro-v3.0.0-midi.zip'\n",
    "#%mv 'maestro-v3.0.0' 'Maestro'\n",
    "\n",
    "!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\n",
    "!unzip 'maestro-v3.0.0-midi.zip'\n",
    "!rm 'maestro-v3.0.0-midi.zip'\n",
    "!mv 'maestro-v3.0.0' 'Maestro'\n",
    "\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "\n",
    "from evaluate import load as load_metric\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator, split_files_for_training\n",
    "from miditok.data_augmentation import augment_dataset\n",
    "from torch import Tensor, argmax\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda import is_available as cuda_available, is_bf16_supported\n",
    "from torch.backends.mps import is_available as mps_available\n",
    "from transformers import AutoModelForCausalLM, MistralConfig, Trainer, TrainingArguments, GenerationConfig\n",
    "from transformers.trainer_utils import set_seed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "set_seed(777)\n",
    "\n",
    "# Our tokenizer's configuration\n",
    "BEAT_RES = {(0, 1): 12, (1, 2): 4, (2, 4): 2, (4, 8): 1}\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": BEAT_RES,\n",
    "    \"num_velocities\": 24,\n",
    "    \"special_tokens\": [\"PAD\", \"BOS\", \"EOS\"],\n",
    "    \"use_chords\": True,\n",
    "    \"use_rests\": True,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": True,\n",
    "    \"use_programs\": False,  # no multitrack here\n",
    "    \"num_tempos\": 32,\n",
    "    \"tempo_range\": (50, 200),  # (min_tempo, max_tempo)\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "\n",
    "# Creates the tokenizer\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "# Trains the tokenizer with Byte Pair Encoding (BPE) to build the vocabulary, here 30k tokens\n",
    "midi_paths = list(Path(\"Maestro\").resolve().glob(\"**/*.mid\")) + list(Path(\"Maestro\").resolve().glob(\"**/*.midi\"))\n",
    "tokenizer.train(\n",
    "    vocab_size=30000,\n",
    "    files_paths=midi_paths,\n",
    ")\n",
    "tokenizer.save_params(\"tokenizer.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare MIDIs for training\n",
    "\n",
    "Here we split the files in three subsets: train, validation and test.\n",
    "Then data augmentation is performed on each subset independently, and the MIDIs are split into smaller chunks that make approximately the desired token sequence length for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split MIDI paths in train/valid/test sets\n",
    "total_num_files = len(midi_paths)\n",
    "num_files_valid = round(total_num_files * 0.15)\n",
    "num_files_test = round(total_num_files * 0.15)\n",
    "shuffle(midi_paths)\n",
    "midi_paths_valid = midi_paths[:num_files_valid]\n",
    "midi_paths_test = midi_paths[num_files_valid:num_files_valid + num_files_test]\n",
    "midi_paths_train = midi_paths[num_files_valid + num_files_test:]\n",
    "\n",
    "# Chunk MIDIs and perform data augmentation on each subset independently\n",
    "for files_paths, subset_name in (\n",
    "    (midi_paths_train, \"train\"), (midi_paths_valid, \"valid\"), (midi_paths_test, \"test\")\n",
    "):\n",
    "\n",
    "    # Split the MIDIs into chunks of sizes approximately about 1024 tokens\n",
    "    subset_chunks_dir = Path(f\"Maestro_{subset_name}\")\n",
    "    split_files_for_training(\n",
    "        files_paths=files_paths,\n",
    "        tokenizer=tokenizer,\n",
    "        save_dir=subset_chunks_dir,\n",
    "        max_seq_len=1024,\n",
    "        num_overlap_bars=2,\n",
    "    )\n",
    "\n",
    "    # Perform data augmentation\n",
    "    augment_dataset(\n",
    "        subset_chunks_dir,\n",
    "        pitch_offsets=[-12, 12],\n",
    "        velocity_offsets=[-4, 4],\n",
    "        duration_offsets=[-0.5, 0.5],\n",
    "    )\n",
    "\n",
    "# Create Dataset and Collator for training\n",
    "midi_paths_train = list(Path(\"Maestro_train\").glob(\"**/*.mid\")) + list(Path(\"Maestro_train\").glob(\"**/*.midi\"))\n",
    "midi_paths_valid = list(Path(\"Maestro_valid\").glob(\"**/*.mid\")) + list(Path(\"Maestro_valid\").glob(\"**/*.midi\"))\n",
    "midi_paths_test = list(Path(\"Maestro_test\").glob(\"**/*.mid\")) + list(Path(\"Maestro_test\").glob(\"**/*.midi\"))\n",
    "kwargs_dataset = {\"max_seq_len\": 1024, \"tokenizer\": tokenizer, \"bos_token_id\": tokenizer[\"BOS_None\"], \"eos_token_id\": tokenizer[\"EOS_None\"]}\n",
    "dataset_train = DatasetMIDI(midi_paths_train, **kwargs_dataset)\n",
    "dataset_valid = DatasetMIDI(midi_paths_valid, **kwargs_dataset)\n",
    "dataset_test = DatasetMIDI(midi_paths_test, **kwargs_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization\n",
    "\n",
    "We will use the [Mistral implementation of Hugging Face](https://huggingface.co/docs/transformers/model_doc/mistral).\n",
    "Feel free to explore the documentation and source code to dig deeper.\n",
    "\n",
    "**You may need to adjust the model's configuration, the training configuration and the maximum input sequence length (cell above) depending on your hardware.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model\n",
    "model_config = MistralConfig(\n",
    "    vocab_size=len(tokenizer),\n",
    "    hidden_size=512,\n",
    "    intermediate_size=2048,\n",
    "    num_hidden_layers=8,\n",
    "    num_attention_heads=8,\n",
    "    num_key_value_heads=4,\n",
    "    sliding_window=256,\n",
    "    max_position_embeddings=8192,\n",
    "    pad_token_id=tokenizer['PAD_None'],\n",
    "    bos_token_id=tokenizer['BOS_None'],\n",
    "    eos_token_id=tokenizer['EOS_None'],\n",
    ")\n",
    "model = AutoModelForCausalLM.from_config(model_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {metric: load_metric(metric) for metric in [\"accuracy\"]}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute metrics for pretraining.\n",
    "\n",
    "    Must use preprocess_logits function that converts logits to predictions (argmax or sampling).\n",
    "\n",
    "    :param eval_pred: EvalPrediction containing predictions and labels\n",
    "    :return: metrics\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    not_pad_mask = labels != -100\n",
    "    labels, predictions = labels[not_pad_mask], predictions[not_pad_mask]\n",
    "    return metrics[\"accuracy\"].compute(predictions=predictions.flatten(), references=labels.flatten())\n",
    "\n",
    "def preprocess_logits(logits: Tensor, _: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Preprocess the logits before accumulating them during evaluation.\n",
    "\n",
    "    This allows to significantly reduce the memory usage and make the training tractable.\n",
    "    \"\"\"\n",
    "    pred_ids = argmax(logits, dim=-1)  # long dtype\n",
    "    return pred_ids\n",
    "\n",
    "# Create config for the Trainer\n",
    "USE_CUDA = cuda_available()\n",
    "if not cuda_available():\n",
    "    FP16 = FP16_EVAL = BF16 = BF16_EVAL = False\n",
    "elif is_bf16_supported():\n",
    "    BF16 = BF16_EVAL = True\n",
    "    FP16 = FP16_EVAL = False\n",
    "else:\n",
    "    BF16 = BF16_EVAL = False\n",
    "    FP16 = FP16_EVAL = True\n",
    "USE_MPS = not USE_CUDA and mps_available()\n",
    "training_config = TrainingArguments(\n",
    "    \"runs\", False, True, True, False, \"steps\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=48,\n",
    "    gradient_accumulation_steps=3,\n",
    "    eval_accumulation_steps=None,\n",
    "    eval_steps=1000,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=3.0,\n",
    "    max_steps=20000,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    warmup_ratio=0.3,\n",
    "    log_level=\"debug\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    no_cuda=not USE_CUDA,\n",
    "    seed=444,\n",
    "    fp16=FP16,\n",
    "    fp16_full_eval=FP16_EVAL,\n",
    "    bf16=BF16,\n",
    "    bf16_full_eval=BF16_EVAL,\n",
    "    load_best_model_at_end=True,\n",
    "    label_smoothing_factor=0.,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=[\"tensorboard\"],\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "collator = DataCollator(tokenizer[\"PAD_None\"], copy_inputs_as_labels=True)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_config,\n",
    "    data_collator=collator,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_valid,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=None,\n",
    "    preprocess_logits_for_metrics=preprocess_logits,\n",
    ")\n",
    "\n",
    "# Training\n",
    "train_result = trainer.train()\n",
    "trainer.save_model()  # Saves the tokenizer too\n",
    "trainer.log_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "OaNkGcFo9UP_"
   },
   "outputs": [],
   "source": [
    "(gen_results_path := Path('gen_res')).mkdir(parents=True, exist_ok=True)\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=200,  # extends samples by 200 tokens\n",
    "    num_beams=1,         # no beam search\n",
    "    do_sample=True,      # but sample instead\n",
    "    temperature=0.9,\n",
    "    top_k=15,\n",
    "    top_p=0.95,\n",
    "    epsilon_cutoff=3e-4,\n",
    "    eta_cutoff=1e-3,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Here the sequences are padded to the left, so that the last token along the time dimension\n",
    "# is always the last token of each seq, allowing to efficiently generate by batch\n",
    "collator.pad_on_left = True\n",
    "collator.eos_token = None\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=16, collate_fn=collator)\n",
    "model.eval()\n",
    "count = 0\n",
    "for batch in tqdm(dataloader_test, desc='Testing model / Generating results'):  # (N,T)\n",
    "    res = model.generate(\n",
    "        inputs=batch[\"input_ids\"].to(model.device),\n",
    "        attention_mask=batch[\"attention_mask\"].to(model.device),\n",
    "        generation_config=generation_config)  # (N,T)\n",
    "\n",
    "    # Saves the generated music, as MIDI files and tokens (json)\n",
    "    for prompt, continuation in zip(batch[\"input_ids\"], res):\n",
    "        generated = continuation[len(prompt):]\n",
    "        midi = tokenizer.decode([deepcopy(generated.tolist())])\n",
    "        tokens = [generated, prompt, continuation]  # list compr. as seqs of dif. lengths\n",
    "        tokens = [seq.tolist() for seq in tokens]\n",
    "        for tok_seq in tokens[1:]:\n",
    "            _midi = tokenizer.decode([deepcopy(tok_seq)])\n",
    "            midi.tracks.append(_midi.tracks[0])\n",
    "        midi.tracks[0].name = f'Continuation of original sample ({len(generated)} tokens)'\n",
    "        midi.tracks[1].name = f'Original sample ({len(prompt)} tokens)'\n",
    "        midi.tracks[2].name = f'Original sample and continuation'\n",
    "        midi.dump_midi(gen_results_path / f'{count}.mid')\n",
    "        tokenizer.save_tokens(tokens, gen_results_path / f'{count}.json') \n",
    "\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Optimus_VIRTUOSO_Multi_Instrumental_RGA_Edition.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
